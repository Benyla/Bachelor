#!/usr/bin/env python3
"""
compute_fid.py

Compute Fréchet Inception Distance (FID) between real validation set samples and
samples generated by a trained VAE model.
"""
import argparse
import os
import torch
import torch.nn.functional as F
import numpy as np
from scipy.linalg import sqrtm
from torchvision.models import inception_v3
from torch.utils.data import DataLoader, TensorDataset

from src.utils.config_loader import load_config
from src.utils.data_loader import get_data, SingleCellDataset
from src.models.VAE import VAE


def get_features(data_loader, device):
    """
    Extract feature activations from a pretrained InceptionV3 model for all samples in data_loader.
    """
    inception = inception_v3(pretrained=True, transform_input=False).to(device)
    inception.eval()
    feats = []
    with torch.no_grad():
        for batch in data_loader:
            # unpack if TensorDataset yields tuple
            if isinstance(batch, (list, tuple)):
                batch = batch[0]
            batch = batch.to(device)
            # convert single-channel to 3-channel
            if batch.dim() == 4 and batch.shape[1] == 1:
                batch = batch.repeat(1, 3, 1, 1)
            # resize to inception input size
            batch = F.interpolate(batch, size=(299, 299), mode='bilinear', align_corners=False)
            preds = inception(batch)
            feats.append(preds.cpu().numpy())
    return np.concatenate(feats, axis=0)


def calculate_activation_statistics(features):
    """
    Compute mean and covariance of feature activations.
    """
    mu = np.mean(features, axis=0)
    sigma = np.cov(features, rowvar=False)
    return mu, sigma


def calculate_fid(mu1, sigma1, mu2, sigma2, eps=1e-6):
    """
    Compute the Fréchet Inception Distance.
    """
    diff = mu1 - mu2
    covmean, _ = sqrtm(sigma1.dot(sigma2), disp=False)
    if np.iscomplexobj(covmean):
        covmean = covmean.real
    fid = diff.dot(diff) + np.trace(sigma1 + sigma2 - 2 * covmean)
    return float(fid)


def generate_images(model, num_samples, latent_dim, device, batch_size):
    """
    Generate images by sampling from the VAE's latent space.
    """
    model.eval()
    imgs = []
    with torch.no_grad():
        for i in range(0, num_samples, batch_size):
            curr = min(batch_size, num_samples - i)
            z = torch.randn(curr, latent_dim).to(device)
            recon = model.decode(z)
            imgs.append(recon.cpu())
    return torch.cat(imgs, dim=0)


def main():
    parser = argparse.ArgumentParser(description="Compute FID for VAE-generated vs real samples")
    parser.add_argument('--config', type=str, required=True, help='Path to YAML config')
    parser.add_argument('--model-path', type=str, required=True, help='Path to VAE checkpoint (.pth)')
    parser.add_argument('--batch-size', type=int, default=32, help='Batch size for feature extraction')
    parser.add_argument('--num-samples', type=int, default=None,
                        help='Number of samples to use (both real and generated); defaults to full val set')
    parser.add_argument('--output', type=str, default='experiments/fid', help='Directory to save FID score')
    args = parser.parse_args()

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Load config and model
    config = load_config(args.config)
    config['model']['checkpoint_path'] = args.model_path
    model = VAE(
        in_channels=config['model']['in_channels'],
        latent_dim=config['model']['latent_dim']
    ).to(device)
    ckpt = torch.load(args.model_path, map_location=device)
    model.load_state_dict(ckpt['model_state_dict'])

    # Prepare real data loader
    _, val_files, _ = get_data()
    real_loader = DataLoader(
        SingleCellDataset(val_files), batch_size=args.batch_size,
        shuffle=False, drop_last=False
    )

    # Extract real features
    real_feats = get_features(real_loader, device)
    num_real = real_feats.shape[0]
    num_samples = args.num_samples or num_real

    # Subsample real features if requested
    if num_samples < num_real:
        idx = np.random.choice(num_real, num_samples, replace=False)
        real_feats = real_feats[idx]

    # Generate images and extract features
    gen_images = generate_images(model, num_samples, config['model']['latent_dim'], device, args.batch_size)
    gen_loader = DataLoader(TensorDataset(gen_images), batch_size=args.batch_size)
    gen_feats = get_features(gen_loader, device)

    # Compute statistics and FID
    mu_real, sigma_real = calculate_activation_statistics(real_feats)
    mu_gen, sigma_gen = calculate_activation_statistics(gen_feats)
    fid_value = calculate_fid(mu_real, sigma_real, mu_gen, sigma_gen)

    # Output results
    os.makedirs(args.output, exist_ok=True)
    out_file = os.path.join(args.output, 'fid_score.txt')
    with open(out_file, 'w') as f:
        f.write(f'{fid_value:.6f}\n')

    print(f'[INFO] FID score: {fid_value:.6f}')
    print(f'[INFO] Saved FID score to {out_file}')

if __name__ == '__main__':
    main()
